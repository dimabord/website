{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "oov_token = '<OOV>'\n",
    "padding_type = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "data = open('irish-lyrics-eof.txt').read()\n",
    "\n",
    "corpus = data.lower().split('\\n')\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "#print(tokenizer.word_index)\n",
    "print(total_words)\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range (1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "#print(input_sequences)\n",
    "\n",
    "max_sequence_len = max(len(x) for x in input_sequences )\n",
    "input_sequences = np.array(pad_sequences(input_sequences,\n",
    "                                         maxlen=max_sequence_len,\n",
    "                                         truncating=trunc_type,\n",
    "                                         padding=padding_type,\n",
    "                                         ))\n",
    "\n",
    "#print(input_sequences)\n",
    "\n",
    "xs = input_sequences[:, :-1]\n",
    "labels = input_sequences[:, -1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "#print(xs)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12038 samples\n",
      "Epoch 1/100\n",
      "12038/12038 [==============================] - 27s 2ms/sample - loss: 6.6231 - accuracy: 0.0755\n",
      "Epoch 2/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 5.7507 - accuracy: 0.1150\n",
      "Epoch 3/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 4.9073 - accuracy: 0.1625\n",
      "Epoch 4/100\n",
      "12038/12038 [==============================] - 27s 2ms/sample - loss: 4.0131 - accuracy: 0.2317\n",
      "Epoch 5/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 3.1842 - accuracy: 0.3335\n",
      "Epoch 6/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 2.5278 - accuracy: 0.4397\n",
      "Epoch 7/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 2.0476 - accuracy: 0.5253\n",
      "Epoch 8/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 1.6725 - accuracy: 0.6057\n",
      "Epoch 9/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 1.4094 - accuracy: 0.6606\n",
      "Epoch 10/100\n",
      "12038/12038 [==============================] - 26s 2ms/sample - loss: 1.2357 - accuracy: 0.7062\n",
      "Epoch 11/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 1.1311 - accuracy: 0.7266\n",
      "Epoch 12/100\n",
      "12038/12038 [==============================] - 27s 2ms/sample - loss: 1.0741 - accuracy: 0.7366\n",
      "Epoch 13/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 1.0905 - accuracy: 0.7265\n",
      "Epoch 14/100\n",
      "12038/12038 [==============================] - 18s 2ms/sample - loss: 1.1084 - accuracy: 0.7216\n",
      "Epoch 15/100\n",
      "12038/12038 [==============================] - 18s 1ms/sample - loss: 1.0840 - accuracy: 0.7232\n",
      "Epoch 16/100\n",
      "12038/12038 [==============================] - 16s 1ms/sample - loss: 1.1627 - accuracy: 0.6991\n",
      "Epoch 17/100\n",
      "12038/12038 [==============================] - 19s 2ms/sample - loss: 1.1954 - accuracy: 0.6955\n",
      "Epoch 18/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 1.0643 - accuracy: 0.7242\n",
      "Epoch 19/100\n",
      "12038/12038 [==============================] - 18s 1ms/sample - loss: 1.0338 - accuracy: 0.7387\n",
      "Epoch 20/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.9389 - accuracy: 0.7598\n",
      "Epoch 21/100\n",
      "12038/12038 [==============================] - 18s 1ms/sample - loss: 0.8885 - accuracy: 0.7691\n",
      "Epoch 22/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.9114 - accuracy: 0.7629\n",
      "Epoch 23/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 0.9101 - accuracy: 0.7606\n",
      "Epoch 24/100\n",
      "12038/12038 [==============================] - 18s 1ms/sample - loss: 0.9432 - accuracy: 0.7578\n",
      "Epoch 25/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.9850 - accuracy: 0.7425\n",
      "Epoch 26/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 1.0499 - accuracy: 0.7251\n",
      "Epoch 27/100\n",
      "12038/12038 [==============================] - 16s 1ms/sample - loss: 1.0822 - accuracy: 0.7188\n",
      "Epoch 28/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 1.0007 - accuracy: 0.7341\n",
      "Epoch 29/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 0.9905 - accuracy: 0.7436\n",
      "Epoch 30/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.9515 - accuracy: 0.7527\n",
      "Epoch 31/100\n",
      "12038/12038 [==============================] - 35s 3ms/sample - loss: 0.9159 - accuracy: 0.7618\n",
      "Epoch 32/100\n",
      "12038/12038 [==============================] - 29s 2ms/sample - loss: 0.8858 - accuracy: 0.7670\n",
      "Epoch 33/100\n",
      "12038/12038 [==============================] - 19s 2ms/sample - loss: 0.8465 - accuracy: 0.7775\n",
      "Epoch 34/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.8788 - accuracy: 0.7675\n",
      "Epoch 35/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.9119 - accuracy: 0.7618\n",
      "Epoch 36/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.9316 - accuracy: 0.7542\n",
      "Epoch 37/100\n",
      "12038/12038 [==============================] - 18s 2ms/sample - loss: 0.9762 - accuracy: 0.7431\n",
      "Epoch 38/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.9711 - accuracy: 0.7457\n",
      "Epoch 39/100\n",
      "12038/12038 [==============================] - 19s 2ms/sample - loss: 0.9678 - accuracy: 0.7416\n",
      "Epoch 40/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.8864 - accuracy: 0.7652\n",
      "Epoch 41/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.8472 - accuracy: 0.7738\n",
      "Epoch 42/100\n",
      "12038/12038 [==============================] - 19s 2ms/sample - loss: 0.8680 - accuracy: 0.7711\n",
      "Epoch 43/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.8573 - accuracy: 0.7748\n",
      "Epoch 44/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.8655 - accuracy: 0.7750\n",
      "Epoch 45/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.8443 - accuracy: 0.7769\n",
      "Epoch 46/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.8264 - accuracy: 0.7819\n",
      "Epoch 47/100\n",
      "12038/12038 [==============================] - 16s 1ms/sample - loss: 0.9052 - accuracy: 0.7580\n",
      "Epoch 48/100\n",
      "12038/12038 [==============================] - 16s 1ms/sample - loss: 0.9810 - accuracy: 0.7452\n",
      "Epoch 49/100\n",
      "12038/12038 [==============================] - 18s 2ms/sample - loss: 0.9507 - accuracy: 0.7489\n",
      "Epoch 50/100\n",
      "12038/12038 [==============================] - 19s 2ms/sample - loss: 0.9503 - accuracy: 0.7508\n",
      "Epoch 51/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.9249 - accuracy: 0.7527\n",
      "Epoch 52/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 0.9622 - accuracy: 0.7419\n",
      "Epoch 53/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.9434 - accuracy: 0.7553\n",
      "Epoch 54/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.8777 - accuracy: 0.7677\n",
      "Epoch 55/100\n",
      "12038/12038 [==============================] - 19s 2ms/sample - loss: 0.8593 - accuracy: 0.7721\n",
      "Epoch 56/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 0.8863 - accuracy: 0.7644\n",
      "Epoch 57/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 0.9593 - accuracy: 0.7432\n",
      "Epoch 58/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 1.0075 - accuracy: 0.7407\n",
      "Epoch 59/100\n",
      "12038/12038 [==============================] - 26s 2ms/sample - loss: 1.0232 - accuracy: 0.7362\n",
      "Epoch 60/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.9386 - accuracy: 0.7518\n",
      "Epoch 61/100\n",
      "12038/12038 [==============================] - 17s 1ms/sample - loss: 0.8606 - accuracy: 0.7756\n",
      "Epoch 62/100\n",
      "12038/12038 [==============================] - 21s 2ms/sample - loss: 0.8133 - accuracy: 0.7844\n",
      "Epoch 63/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.7845 - accuracy: 0.7933\n",
      "Epoch 64/100\n",
      "12038/12038 [==============================] - 20s 2ms/sample - loss: 0.7773 - accuracy: 0.7886\n",
      "Epoch 65/100\n",
      "12038/12038 [==============================] - 27s 2ms/sample - loss: 0.7940 - accuracy: 0.7855\n",
      "Epoch 66/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.8668 - accuracy: 0.7680\n",
      "Epoch 67/100\n",
      "12038/12038 [==============================] - 26s 2ms/sample - loss: 0.9015 - accuracy: 0.7592\n",
      "Epoch 68/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.9704 - accuracy: 0.7459\n",
      "Epoch 69/100\n",
      "12038/12038 [==============================] - 26s 2ms/sample - loss: 0.9513 - accuracy: 0.7491\n",
      "Epoch 70/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.9071 - accuracy: 0.7577\n",
      "Epoch 71/100\n",
      "12038/12038 [==============================] - 26s 2ms/sample - loss: 0.8880 - accuracy: 0.7657\n",
      "Epoch 72/100\n",
      "12038/12038 [==============================] - 26s 2ms/sample - loss: 0.8453 - accuracy: 0.7775\n",
      "Epoch 73/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.8131 - accuracy: 0.7858\n",
      "Epoch 74/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.8279 - accuracy: 0.7801\n",
      "Epoch 75/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.8193 - accuracy: 0.7841\n",
      "Epoch 76/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.7975 - accuracy: 0.7863\n",
      "Epoch 77/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.7890 - accuracy: 0.7883\n",
      "Epoch 78/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.8096 - accuracy: 0.7854\n",
      "Epoch 79/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.8465 - accuracy: 0.7764\n",
      "Epoch 80/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.9114 - accuracy: 0.7613\n",
      "Epoch 81/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 0.9648 - accuracy: 0.7515\n",
      "Epoch 82/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.9625 - accuracy: 0.7515\n",
      "Epoch 83/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.9511 - accuracy: 0.7565\n",
      "Epoch 84/100\n",
      "12038/12038 [==============================] - 22s 2ms/sample - loss: 0.8793 - accuracy: 0.7676\n",
      "Epoch 85/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.8501 - accuracy: 0.7762\n",
      "Epoch 86/100\n",
      "12038/12038 [==============================] - 29s 2ms/sample - loss: 0.8164 - accuracy: 0.7831\n",
      "Epoch 87/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.8003 - accuracy: 0.7878\n",
      "Epoch 88/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 1.0068 - accuracy: 0.7440\n",
      "Epoch 89/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 1.0170 - accuracy: 0.7372\n",
      "Epoch 90/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.9614 - accuracy: 0.7477\n",
      "Epoch 91/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.9295 - accuracy: 0.7600\n",
      "Epoch 92/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.8543 - accuracy: 0.7785\n",
      "Epoch 93/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.8011 - accuracy: 0.7839\n",
      "Epoch 94/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.7637 - accuracy: 0.7952\n",
      "Epoch 95/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.7470 - accuracy: 0.8015\n",
      "Epoch 96/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.7499 - accuracy: 0.7993s - loss: 0.7460 \n",
      "Epoch 97/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.7657 - accuracy: 0.7968\n",
      "Epoch 98/100\n",
      "12038/12038 [==============================] - 25s 2ms/sample - loss: 0.8458 - accuracy: 0.7798\n",
      "Epoch 99/100\n",
      "12038/12038 [==============================] - 24s 2ms/sample - loss: 0.9447 - accuracy: 0.7506\n",
      "Epoch 100/100\n",
      "12038/12038 [==============================] - 23s 2ms/sample - loss: 0.9394 - accuracy: 0.7541\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#Callbacks = myCallback()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len - 1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(xs, ys, epochs = 100, verbose = 1, )#callbacks=[Callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"irish_poetry.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "loaded_model = tf.keras.models.load_model('irish_poetry.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poem(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding=padding_type)\n",
    "        predicted = loaded_model.predict_classes(token_list, verbose=0)\n",
    "        output_word=''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += ' ' + word\n",
    "    results = seed_text\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arina is going by the road to Dublin life has ever a heart of my own gone alas on like our youth too soon deprived in gone and shes gone home gone so mild gone away on the love in my tune before proud saxon lord gone host'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_poem('Arina is going by the road to Dublin', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
